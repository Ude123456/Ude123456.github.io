<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>散列表</title>
      <link href="/2022/11/14/san-lie-biao/"/>
      <url>/2022/11/14/san-lie-biao/</url>
      
        <content type="html"><![CDATA[<hr><blockquote><p>顺序存储的结构类型有顺序表、栈、队列等，但他们都需要一个一个地按顺序对元素进行访问，如果要访问的总量很大时候，并且当我们要访问的这一元素位于末尾时，则查找效率就会很低。<br>散列表是一种<strong>空间换时间</strong>的存储结构，就是牺牲了存储空间来换取了查找数据的效率，但是如果需要的存储空间太大时，也会让我们感到头疼，所以我们往往需要在空间和时间两者当中进行权衡。</p></blockquote><hr><h2 id="1、什么是散列表"><a href="#1、什么是散列表" class="headerlink" title="1、什么是散列表"></a>1、什么是散列表</h2><p>如果在图书馆里要找一本书，那我们应该不会从第 1 本书一直找下去，因为这样实在是太慢了。回想一下我们到图书馆找书是怎么找的呢？首先是不是应该先找到你要找的这本书属于什么类别，例如科幻类、古典文学、武侠类等等，然后再在这一个类别当中进行查找。</p><p>还有我们平常学英语应该也要查字典，那么要查找一个单词的时候，我们肯定不会从头翻到尾，而是首先通过这个单词的首字母，找到对应的那一页；再找第 2 个字母、第 3 个字母……这样可以快速跳到那个单词所在的页。</p><p>其实这些就是运用了散列表的思想：在记录的存储地址和它的关键码之间建立一个确定的对应关系。这样，不需要经过比较，一次读取就能够得到所查元素。</p><p>散列表（Hash table，也叫哈希表），是<strong>根据键（Key）而直接访问在内存储存位置</strong>的数据结构。也就是说，它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度。<strong>这个映射函数称做散列函数，存放记录的数组称做散列表，由散列函数所得的存储地址称做散列地址</strong>。<br><img src="/2022/11/14/san-lie-biao/%E5%9B%BE1.png"><br>从上图中，我们也可以看出散列表不仅仅只是一种查找技术，同时也是一种存储技术。另外，从散列表的定义，我们也可以发现，散列方法是不适用于范围查找的，换言之，在散列表中，我们不可能找到最大或最小关键码的记录，也不可能找到在某一范围内的记录。</p><p>那么散列表的关键值都要不同，这时我们会发现出现一个严重的问题，如果对于两个不同的数据 ，我们计算到了同样的键值，那么就会出现冲突，此时该如何处理呢？</p><p>所以构造一个好的散列表，最重要的是做好以下两个步骤：</p><ol><li>设计一个”好”的散列函数来计算Key值。(好的哈希函数应尽可能避免冲突的出现，而且计算时应尽可能简洁快速)</li><li>出现了冲突时又该如何调整插入元素。</li></ol><hr><h2 id="2、散列函数设计方法"><a href="#2、散列函数设计方法" class="headerlink" title="2、散列函数设计方法"></a>2、散列函数设计方法</h2><h3 id="1、直接寻址法"><a href="#1、直接寻址法" class="headerlink" title="1、直接寻址法"></a>1、直接寻址法</h3><p>散列函数是关键码的线性函数，即：<br>     $$H(key)&#x3D;a\times key + b$$    式中，a 和 b 是常数</p><p>例如：关键码集合为{10,20,30,40,60,80,90}，选取一个散列函数为：$H(key)&#x3D;\frac{1}{10}key$ ,则散列表为：<br><img src="/2022/11/14/san-lie-biao/%E5%9B%BE2.png"><br>适用情况：事先知道关键码，关键码集合<strong>不是很大并且连续性较好</strong>。</p><h3 id="2、除留余数法"><a href="#2、除留余数法" class="headerlink" title="2、除留余数法"></a>2、除留余数法</h3><p>假设散列表长度为 n，取一个不大于 n 但近似接近或等于 m 的质数 p，利用除留余数法的散列函数把关键字转换成散列地址。</p><p>散列函数为：<br>     $$H(key)&#x3D;key\quad mod\quad p$$    </p><p>例如，数据元素集合为a&#x3D;{78,7,99,13,25,53,59,30}，哈希表长度n取11时，并不会产生哈希冲突；当n取9时，就会产生哈希冲突。p的选取并不是固定的，需要自己进行判断，以此来选择最合适的p值。</p><p>通常情况下，哈希表的长度n习惯选取<strong>质数</strong>。<strong>对p的选择也十分重要，一般取素数或m</strong>，这样可以有效减少哈希冲突的发生。</p><p>在来看一个例子：现在有一组关键码，我们取p&#x3D;21，则会得到以下信息：<br><img src="/2022/11/14/san-lie-biao/%E5%9B%BE3.png"><br>适用情况：除留余数法是一种最简单、也是最常见的构造散列函数的方法，并且<strong>不需要事先知道关键码的分布</strong>。</p><h3 id="3、数字分析法"><a href="#3、数字分析法" class="headerlink" title="3、数字分析法"></a>3、数字分析法</h3><p>如果关键字是位数较多的数字（比如手机号和学号），且这些数字部分存在相同规律，则可以采用抽取剩余不同规律部分作为散列地址。</p><p>如下图所示，有80个记录，每一行为一个记录中的键，假设表长为100，则可取两位十进制数组成哈希地址。<br><img src="/2022/11/14/san-lie-biao/%E5%9B%BE4.png"><br>通过对上图进行观察可以得出，第1,2列对应的数字都是相同的，而第3列和第8列存在着大量重复的数字（分别是3和2,7），因此不能选择它们成为哈希地址。而中间4位可以看作是随机的，所以可以从中任选两位作为哈希地址。</p><p>再来看一个更直白的应用，现在有一组学生的学号为：<br><img src="/2022/11/14/san-lie-biao/%E5%9B%BE5.png"><br>这组学号的前7位取值相对比较集中，剩下的后两位取值较均匀，可以直接使用学号的最后两位作为哈希地址，所以这十个关键字的哈希地址分别为：<br>10、21、71、85、13、37、22、33、3、14。</p><p>适用情况：能预先估计出关键码的每一位上各种数字出现的频度，不同的关键码集合需要重新分析。</p><h3 id="4、平方取中法"><a href="#4、平方取中法" class="headerlink" title="4、平方取中法"></a>4、平方取中法</h3><p>对关键码平方后，按散列表大小，取中间若干位作为散列地址（<strong>平方</strong>后<strong>截取</strong>）。</p><p>它弥补了数字分析法的一些缺陷，因为我们有时并不能知道键的全部情况，取其中几位也不一定合适，而一个数平方后的中间几个数和原数的每一位都相关，由此我们就能得到随机性更强的哈希地址取的位数由表长决定。<br><img src="/2022/11/14/san-lie-biao/%E5%9B%BE6.png"><br>适用情况：事先不知道关键码的分布并且<strong>关键码的位数不是很大</strong>。</p><h3 id="5、折叠法"><a href="#5、折叠法" class="headerlink" title="5、折叠法"></a>5、折叠法</h3><p>将关键字从左到右分割成位数相等的几部分（注意最后一部分位数不够时可以短些），然后将这几部分叠加求和，并按散列表表长，取后几位作为散列地址。</p><p>例如：设关键码为<u>2 5 3</u> <u>4 6 3</u> <u>5 8 7</u> <u>0 5</u>，散列地址为三位。<br><img src="/2022/11/14/san-lie-biao/%E5%9B%BE7.png"><br>适用情况：<strong>关键码很多</strong>，事先不知道关键码的分布。</p><hr><h2 id="3、解决冲突的方法"><a href="#3、解决冲突的方法" class="headerlink" title="3、解决冲突的方法"></a>3、解决冲突的方法</h2><p>我们在前面已经说过了，我们在构建散列表时，一个经常会碰到的问题是：不同的关键值经过散列函数的映射后，得到了一个同样的散列地址，这种现象就叫做冲突。那我们该如何解决冲突呢，方法总共有两类：开放定址法和拉链法。</p><p>用开放定址法处理冲突得到的散列表叫<strong>闭散列表</strong>；用拉链法处理冲突构造出的散列表叫<strong>开散列表</strong>。</p><h3 id="1、开放定址法"><a href="#1、开放定址法" class="headerlink" title="1、开放定址法"></a>1、开放定址法</h3><p>当一个关键字和另一个关键字发生冲突时，使用某种探测技术在Hash表中形成一个探测序列，然后沿着这个探测序列依次查找下去，当碰到一个空的单元时，则插入其中。<br>基本公式为：**$H(key) &#x3D; (key+di)\quad mod\quad TableSize$<strong>。注意，这里是一个递归序列，</strong>其中di为增量序列，TableSize为散列表长**。<br>根据di的不同我们又可以分为线性探测，平方（二次）探测，随机探测。</p><h4 id="1、线性探测法"><a href="#1、线性探测法" class="headerlink" title="1、线性探测法"></a>1、线性探测法</h4><p>以增量序列 1，2，……，（TableSize -1）进行循环试探下一个存储地址，即di &#x3D; i。</p><p>例：关键码集合为{47,7,29,11,16,92,22,8,3}，散列表表长为11，散列函数为$H(key)&#x3D;key\quad mod\quad 11 $，用线性探测法处理冲突，则散列表为：<br><img src="/2022/11/14/san-lie-biao/%E5%9B%BE8.png"><br>通过上图，我们会发现计算散列地址时，较多的元素计算出散列地址为7，图中出现了<strong>堆积</strong>（在处理冲突的过程中会出现<strong>非同义词</strong>之间对同一个散列地址争夺的现象，这种现象就称为堆积现象。）的现象，明明还有空间，却都往一个地方挤。堆积地方的冲突会越来越多。</p><h4 id="2、平方探测法"><a href="#2、平方探测法" class="headerlink" title="2、平方探测法"></a>2、平方探测法</h4><p>以增量序列1^2^，-1^2^，2^2^，-2^2^，……，q^2^，-q^2^ 且q ≤ $\frac{TableSize}{2}$进行循环试探下一个存储地址。</p><p>同上一个例子相同，关键码集合、散列表和散列函数均不做改变，用平方探测法处理冲突，则散列表为：<br><img src="/2022/11/14/san-lie-biao/%E5%9B%BE9.png"><br>我们可以发现平方探测法是跳着寻找位置的，那么就会存在一个问题，假设散列表中还有空间，平方探测(二次探测)就一定能找得到？举个例子说明一下：<br><img src="/2022/11/14/san-lie-biao/%E5%9B%BE10.png"><br>散列函数为$H(key)&#x3D;key\quad mod\quad 5$，用平方探测来处理冲突。<br>我们假设下一个插入11，则H(11)&#x3D;1，探测序列：1+1&#x3D;2, 1-1&#x3D;0, (1+2^2^) mod 5&#x3D;0, (1-2^2^) mod 5&#x3D;2，(1+3^2^) mod 5&#x3D;0, (1-3^2^) mod 5&#x3D;2, (1+4^2^) mod 5&#x3D;2,$\cdots\cdots$我们可以看到，存放11元素的地址在地址0与地址2之间往复横跳，虽然地址3和地址4位置是有空位，但是却找不到这个空间。<strong>解决方法</strong>：有定理显示，如果散列表长度TableSize是某个$\color{red}{4k+3}$（k是正整数)形式的$\color{red}{素数}$时，平方探测法就可以探查到整个散列表空间。</p><h4 id="3、随机探测法"><a href="#3、随机探测法" class="headerlink" title="3、随机探测法"></a>3、随机探测法</h4><p>以增量序列是伪随机数来进行循环试探下一个存储地址。</p><p>计算机产生随机数的方法通常采用线性同余法，<br>$$ 函数名&#x3D;\begin{cases}<br>a_0&#x3D;d &amp;  \<br>a_n&#x3D;(ba_{n-1}+c);mod;m &amp; n&#x3D;1,2,\cdots \<br>\end{cases}$$<br>其中，d称为随机种子。当b、c和m的值确定后，给定一个随机种子，产生确定的随机数序列。</p><h3 id="2、拉链法（链地址法）"><a href="#2、拉链法（链地址法）" class="headerlink" title="2、拉链法（链地址法）"></a>2、拉链法（链地址法）</h3><p>对于不同的关键字可能会通过散列函数映射到同一地址，为避免非同义词发生冲突，把所有散列地址相同的记录，即所有同义词记录存储在一个线性链表中（称为同义词子表），在散列表中存储的是所有同义词子表的头指针。最开始我们已经说过了，用拉链法处理冲突构造出的散列表叫做<strong>开散列表</strong>。开散列表是不会出现堆积现象的。设n个记录存储在长度为m的散列表中，则同义词子表的平均长度为$\frac{n}{m}$。</p><p>关键字序列为 {15,16,29,37,48,12,25,56,67,47,22,34}，应用拉链法处理冲突的散列表如下图所示：<br><img src="/2022/11/14/san-lie-biao/%E5%9B%BE11.png"><br>当单链表无法满足查找需求时，或者说单链表过长导致查找效率过低时，我们可以将单链表改成平衡二叉树或者红黑树进行数据的存储和查找，如下图所示：<br><img src="/2022/11/14/san-lie-biao/%E5%9B%BE12.png"></p><h2 id="4、散列查找的性能分析"><a href="#4、散列查找的性能分析" class="headerlink" title="4、散列查找的性能分析"></a>4、散列查找的性能分析</h2><ul><li><p>由于冲突的存在，产生冲突后的查找仍然是给定值与关键码进行比较的过程。</p></li><li><p>在查找过程中，关键码的比较次数取决于产生冲突的概率。影响冲突产生的因素有：<br>（1）散列函数是否均匀<br>（2）处理冲突的方法<br>（3）散列表的装载因子<br>       $$\alpha&#x3D; \frac{表中填入的记录数}{散列表的长度}$$</p></li><li><p>几种处理冲突方法的<strong>平均查找长度（ASL）</strong><br><img src="/2022/11/14/san-lie-biao/%E5%9B%BE13.png"></p><blockquote><p>散列表的平均查找长度是$\color{red}{装填因子\alpha的函数}$，而不是查找集合中记录个数n的函数。在很多情况下，散列表的空间都比查找集合大，此时虽然浪费了一定的空间，但换来的是查找效率。</p></blockquote></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 哈希表 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>红黑树</title>
      <link href="/2022/11/12/hong-hei-shu/"/>
      <url>/2022/11/12/hong-hei-shu/</url>
      
        <content type="html"><![CDATA[<hr><blockquote><p>学过了二叉查找树还有平衡二叉树以后，再看点更复杂的树形结构——红黑树，跟平衡二叉树一样，红黑树也是为了解决二叉搜索树不能自平衡的问题。红黑树是2-3树的变形，以2-3树的角度去理解红黑树会容易的多。</p></blockquote><hr><p>先回忆一下AVL树：<br><img src="/2022/11/12/hong-hei-shu/%E5%9B%BE1.png"><br>AVL树就是要保证插入节点后，任一节点对应的两棵子树的最大高度差为1，这样就可以保证整棵树的深度最小。</p><p>AVL虽然高度平衡，但是我们发现它每次插入或者删除节点的时候，树的平衡都可能被打破，而且如果要一直保证也就是动态的来使得这个 AVL 树达到平衡是需要很多操作的，太多步的操作反而会影响这个树形结构的的性能。除非是在树结构变化特别少的情况，不然我们让AVL 树平衡的时候，搜索性能的提升可能还不够抵消平衡树所带来的性能消耗。所以就相继出现了2-3树和红黑树。</p><hr><h2 id="1、2-3树"><a href="#1、2-3树" class="headerlink" title="1、2-3树"></a>1、2-3树</h2><h3 id="1、什么是2-3树"><a href="#1、什么是2-3树" class="headerlink" title="1、什么是2-3树"></a>1、什么是2-3树</h3><p>2-3树的意思就是说，一个父节点可以有两个子节点，也可以有三个子节点，并且其也满足类似二叉搜索树的定义（父节点的值大于左子树，但小于右子树），所有叶子节点都在同一层。</p><p>2-3树的某个节点会有两种可能，一是正常的2节点，二是3节点：</p><ul><li>2节点：父亲节点存储一个值，最多有左右两个子树。假设父节点为p，子节点为l(左节点)、r(有节点)，且满足：<br>$$l &lt; p &lt; r$$<br>如下图：<br><img src="/2022/11/12/hong-hei-shu/%E5%9B%BE2.png"></li><li>3节点：父亲节点存储两个值，最多有左中右三个子树。假设父节点分别为p1,p2，子节点分别为l(左节点)、m(中间节点)、r(右节点)，且满足：<br>$<br>\begin{cases}<br>l &lt; p1\<br>p1 &lt; m &lt; p2\<br>r &gt; p2<br>\end{cases}<br>$<br>如下图：<br><img src="/2022/11/12/hong-hei-shu/%E5%9B%BE3.png"><br>一颗完整的2-3树就如下图所示：<br><img src="/2022/11/12/hong-hei-shu/%E5%9B%BE4.png"></li></ul><h3 id="2、2-3树的创建"><a href="#2、2-3树的创建" class="headerlink" title="2、2-3树的创建"></a>2、2-3树的创建</h3><p>假设有一组数据集合数组为**{ 30, 13, 7, 43, 23, 12, 9, 33, 42, 21, 18, 6, 3, 50 }。**</p><p>创建2-3树的过程：</p><p>1、将30作为根节点<br><img src="/2022/11/12/hong-hei-shu/%E5%9B%BE5.png"><br>2、插入13，13比30小，融合成一个值为（13  30）的3节点<br><img src="/2022/11/12/hong-hei-shu/%E5%9B%BE6.png"><br>3、插入7，7比13小，融合成一个值为（7  13  30）的4节点，然后分解<br><img src="/2022/11/12/hong-hei-shu/%E5%9B%BE7.png"><br>4、插入43，43大于13，43大于30，与30一起融合成3节点<br><img src="/2022/11/12/hong-hei-shu/%E5%9B%BE8.png"><br>5、插入23，23大于13，23小于30，与（30  43）融合成4节点，然后分解<br><img src="/2022/11/12/hong-hei-shu/%E5%9B%BE9.png"><br>6、插入12，12小于13，12大于7，与7融合成3节点<br><img src="/2022/11/12/hong-hei-shu/%E5%9B%BE10.png"><br>7、插入9，9小于13，9大于7，9小于12，与（7  12）融合成4节点，然后分解。分解后9升级到上一层，与（13  30）融合成4节点，再次分解<br><img src="/2022/11/12/hong-hei-shu/%E5%9B%BE11.png"><br>8、插入33，33大于13，33大于30，33小于43，与43融合成3节点<br><img src="/2022/11/12/hong-hei-shu/%E5%9B%BE12.png"><br>9、插入42，42大于13，42大于30，42大于33，42小于43，与（33  43）融合成4节点，然后分解<br><img src="/2022/11/12/hong-hei-shu/%E5%9B%BE13.png"><br>10、省略后面过程，最终生成结果为：<br><img src="/2022/11/12/hong-hei-shu/%E5%9B%BE14.png"><br>至此，我们创建了一颗2-3树，可以看出2-3树的平衡性还是很好的。</p><h2 id="2、红黑树"><a href="#2、红黑树" class="headerlink" title="2、红黑树"></a>2、红黑树</h2><hr><blockquote><p>尽管有平衡二叉树和2-3树了，但是现在用的多的还是红黑树，主要是因为红黑树有这4点的优势：<br>1、AVL的左右子树高度差不能超过1，每次进行插入&#x2F;删除操作时，几乎都需要通过旋转操作保持平衡。<br>2、在频繁进行插入&#x2F;删除的场景中，频繁的旋转操作使得AVL的性能大打折扣。<br>3、红黑树通过牺牲严格的平衡，换取插入&#x2F;删除时少量的旋转操作，整体性能优于AVL。（红黑树插入时的不平衡，不超过两次旋转就可以解决；删除时的不平衡，不超过三次旋转就能解决。）<br>4、红黑树的红黑规则，保证最坏的情况下，也能在O(log2N)时间内完成查找操作。</p></blockquote><hr><h3 id="1、将2-3树转换成红黑树"><a href="#1、将2-3树转换成红黑树" class="headerlink" title="1、将2-3树转换成红黑树"></a>1、将2-3树转换成红黑树</h3><p>创建了一棵2-3树以后，我们就可以进行一些结构上的变化<br>将所有的3节点进行变换，并且满足三个条件：</p><ul><li>红链接均为左链接。</li><li>没有任何一个节点同时和两条红链接相连。</li><li>任意空链接到根节点路径上的黑色连接数目相同。</li></ul><p>这三个条件均满足以后我们创建的就是一棵不那么标准的红黑树，如下图：<br><img src="/2022/11/12/hong-hei-shu/%E5%9B%BE15.png"></p><h3 id="2、红黑树的性质"><a href="#2、红黑树的性质" class="headerlink" title="2、红黑树的性质"></a>2、红黑树的性质</h3><p>红黑树本身是一棵二叉查找树，在其基础上附加了两个要求：</p><ul><li>树中的每个结点增加了一个用于存储颜色的标志域；</li><li>树中没有一条路径比其他任何路径长出两倍，整棵树要接近于“平衡”的状态。</li></ul><hr><blockquote><p>路径：指的是从任何一个结点开始，一直到其子孙的叶子结点的长度；<br>接近于平衡：红黑树并不是平衡二叉树，只是由于对各路径的长度之差有限制，所以近似于平衡的状态。</p></blockquote><hr><p>下面图示的就是一棵典型的红黑树：<br><img src="/2022/11/12/hong-hei-shu/%E5%9B%BE16.png"></p><hr><blockquote><p>观察上图，可以发现红黑树的一些规律：<br>1、这些节点<strong>不是红色的就是黑色的</strong>，但是<strong>根节点是黑色的</strong>。<br>2、再看叶子节点，叶子节点跟普通的树不太一样，<strong>红黑树的叶子节点都是null节点（空节点）并且都为黑色的</strong>。<br>3、假设从根节点出发，然后从最左边的路径走到叶子节点，都没有连续的红色节点。所以可以得出一个结论，<strong>同一路径，不存在连续的红色节点</strong>。<br>以上观察出来的这三条规律就是红黑规则的一部分。</p></blockquote><hr><p>因此我们就可以得出红黑树的红黑规则了：</p><ul><li>性质1：每个节点要么是黑色，要么是红色。</li><li>性质2：根节点是黑色。</li><li>性质3：每个叶子节点（NIL）是黑色。</li><li>性质4：每个红色结点的两个子结点一定都是黑色。</li><li>性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。</li><li>从性质5又可以推出：<br>    性质5.1：如果一个结点存在黑子结点，那么该结点肯定有两个子结点</li></ul><h3 id="3、红黑树的术语约定"><a href="#3、红黑树的术语约定" class="headerlink" title="3、红黑树的术语约定"></a>3、红黑树的术语约定</h3>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二叉树，2-3树，红黑树 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>最短路径(Dijkstra算法)</title>
      <link href="/2021/11/12/zui-duan-lu-jing-dijkstra-suan-fa/"/>
      <url>/2021/11/12/zui-duan-lu-jing-dijkstra-suan-fa/</url>
      
        <content type="html"><![CDATA[<hr><blockquote><p>Dijkstra算法刚接触时确实有点难以理解，尤其是代码的实现，但其背后的逻辑实际上是用贪心算法来支撑的。但是在算法学习中Dijkstra算法又是最基本的一种算法，对于求解单源最短路径有着极大的作用。在这里我简单讲一下自己的理解，我的代码参考了《图解数据结构》，该代码适合稠密图，使用的是邻接矩阵来存储的图。 </p></blockquote><hr><h2 id="1、Dijkstra算法主要步骤"><a href="#1、Dijkstra算法主要步骤" class="headerlink" title="1、Dijkstra算法主要步骤"></a>1、Dijkstra算法主要步骤</h2><p><img src="/2021/11/12/zui-duan-lu-jing-dijkstra-suan-fa/Dijkstra%E7%AE%97%E6%B3%95%E6%AD%A5%E9%AA%A4.png"></p><p>对于贪心算法，简单描述一下：<br>贪心算法正如其名字一样，贪心算法只注重眼前利益，就像贪心的小人一样，因此得名贪心算法，该算法即从一个初始解，一步步选取当前最优解，最终得出近似的最优解（注意：不一定是该问题的最优解，而是近似于最优解）。<br>实现该算法的基本过程如下。<br>（1）从问题的某一初始解出发。<br>（2）while能向给定总目标前进一步。<br>（3）求出可行解的一个解元素。<br>（4）由所有解元素组合成问题的一个可行解。<br>（想更深入了解请参考链接<a href="https://blog.csdn.net/effective_coder/article/details/8736718?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164621206116781685343755%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=164621206116781685343755&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-8736718.pc_search_result_control_group&amp;utm_term=%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3&amp;spm=1018.2226.3001.4187%EF%BC%89">https://blog.csdn.net/effective_coder/article/details/8736718?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164621206116781685343755%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=164621206116781685343755&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-8736718.pc_search_result_control_group&amp;utm_term=%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3&amp;spm=1018.2226.3001.4187）</a></p><hr><h2 id="2、Dijkstra算法小结"><a href="#2、Dijkstra算法小结" class="headerlink" title="2、Dijkstra算法小结"></a>2、Dijkstra算法小结</h2><p> 1、Dijkstra算法一般是用来解决单源最短路径问题（指定一个点（源点）到其余各个顶点的最短路径，也叫做“单源最短路径”。）<br> 2、其时间复杂度仅为O(n^2^)，并且非常高效，甚至可以优化成O(log2n)。<br> 3、Dijkstra算法中权值只能为正数，若权值为负数则不能使用该算法。（权值即图各个边所赋予的值）  </p><hr><h2 id="3、算法实现"><a href="#3、算法实现" class="headerlink" title="3、算法实现"></a>3、算法实现</h2><pre class="line-numbers language-C++" data-language="C++"><code class="language-C++">#include &lt;iostream&gt;#include &lt;iomanip&gt; using namespace std; #define SIZE 7#define NUMBER 6#define INFINITE 123456  &#x2F;&#x2F;宏定义无穷大 &#x2F;&#x2F;首先定义图的数组int Graph_Matrix[SIZE][SIZE];int Distance[SIZE];  &#x2F;&#x2F;路径长度 &#x2F;&#x2F;建立有向图void Create_Graph(int *Path_Cost)&#123;    int i,j;    for(i&#x3D;0;i&lt;SIZE;i++)    &#123;        for(j&#x3D;0;j&lt;SIZE;j++)        &#123;            &#x2F;&#x2F;若是在对角线上，设置元素值为0            if(i&#x3D;&#x3D;j)            &#123;                Graph_Matrix[i][j]&#x3D;0;            &#125;            &#x2F;&#x2F;其他位置元素的值为无穷大            else            &#123;                Graph_Matrix[i][j]&#x3D;INFINITE;            &#125;        &#125;    &#125;     int End_Point,Start_Point;  &#x2F;&#x2F;图的边起始位置和终止位置     &#x2F;&#x2F;存入图的各个数据：边，权重    i&#x3D;0;    while(i&lt;SIZE)    &#123;        Start_Point&#x3D;Path_Cost[i*3];  &#x2F;&#x2F;在邻接矩阵中的行        End_Point&#x3D;Path_Cost[i*3+1];  &#x2F;&#x2F;在邻接矩阵中的列        &#x2F;&#x2F;图各边权值转化为邻接矩阵中所在的位置        Graph_Matrix[Start_Point][End_Point]&#x3D;Path_Cost[i*3+2];        i++;    &#125;&#125; &#x2F;&#x2F;打印邻接矩阵void Print_Matrix()&#123;    int i&#x3D;0,j&#x3D;0;    for(i&#x3D;1;i&lt;SIZE;i++)    &#123;        cout &lt;&lt; &quot;vex&quot; &lt;&lt; i ;        for(j&#x3D;1;j&lt;SIZE;j++)        &#123;            &#x2F;&#x2F;为了美观和可读性，将值为无穷大的元素打印为x            if(Graph_Matrix[i][j]&#x3D;&#x3D;INFINITE)            &#123;                cout &lt;&lt; setw(5) &lt;&lt; &quot;x&quot;;            &#125;            else            &#123;                cout &lt;&lt; setw(5) &lt;&lt; Graph_Matrix[i][j];            &#125;        &#125;        cout &lt;&lt; endl;    &#125;&#125; &#x2F;&#x2F;开始求解单源最短路径void Shortest_Path(int vertex1,int vertex_total)&#123;    int Shortest_vertex&#x3D;1;  &#x2F;&#x2F;初始化    int Shortest_distance;  &#x2F;&#x2F;最短距离    int flag[SIZE];  &#x2F;&#x2F;标志数组，标志顶点是否已经遍历过    int i,j;     for(i&#x3D;1;i&lt;&#x3D;vertex_total;i++)    &#123;        flag[i]&#x3D;0;  &#x2F;&#x2F;初始化标志数组        Distance[i]&#x3D;Graph_Matrix[vertex1][i];  &#x2F;&#x2F;将图的权值存入Distance[]数组中    &#125;     flag[vertex1]&#x3D;1;  &#x2F;&#x2F;标志该顶点已经找过    Distance[vertex1]&#x3D;0;  &#x2F;&#x2F;顶点到该顶点自身的距离为0     for(i&#x3D;0;i&lt;&#x3D;vertex_total-1;i++)    &#123;        Shortest_distance&#x3D;INFINITE;        for(j&#x3D;0;j&lt;&#x3D;vertex_total;j++)        &#123;            &#x2F;&#x2F;找到最小权边的顶点            if(flag[j]&#x3D;&#x3D;0 &amp;&amp; Distance[j]&lt;&#x3D;Shortest_distance)            &#123;                Shortest_distance&#x3D;Distance[j];                Shortest_vertex&#x3D;j;            &#125;        &#125;         flag[Shortest_vertex]&#x3D;1;  &#x2F;&#x2F;找到下一个顶点后标记为已经经过         for(j&#x3D;0;j&lt;&#x3D;vertex_total;j++)        &#123;            &#x2F;&#x2F;以上一个顶点为父节点，若前一个顶点和下一个权边的和最小，则更新最短路径            if(flag[j]&#x3D;&#x3D;0 &amp;&amp;               Distance[Shortest_vertex]+Graph_Matrix[Shortest_vertex][j]               &lt;Distance[j])            &#123;                &#x2F;&#x2F;更新最短路径                Distance[j]&#x3D;Distance[Shortest_vertex]+Graph_Matrix[Shortest_vertex][j];            &#125;        &#125;    &#125;&#125; int main()&#123;    int Path_Cost[9][3]&#x3D;&#123;&#123;1,2,3&#125;,&#123;1,3,5&#125;,&#123;1,4,1&#125;,&#123;1,5,3&#125;,&#123;1,6,4&#125;,                         &#123;2,5,3&#125;,&#123;4,5,7&#125;,&#123;4,6,6&#125;,&#123;4,3,2&#125;&#125;;    cout &lt;&lt; &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;  &lt;&lt; endl;    cout &lt;&lt; &quot;此范例图的邻接矩阵如下：&quot; &lt;&lt; endl;    cout &lt;&lt; &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot; &lt;&lt; endl;    cout &lt;&lt; &quot;顶点   vex1 vex2 vex3 vex4 vex5 vex6&quot; &lt;&lt; endl;    Create_Graph(&amp;Path_Cost[0][0]);    Print_Matrix();    cout &lt;&lt; &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;  &lt;&lt; endl;    cout &lt;&lt; &quot;顶点1到各顶点最短距离的最终结果&quot; &lt;&lt; endl;    cout &lt;&lt; &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;  &lt;&lt; endl;    &#x2F;&#x2F;查找最短路径    Shortest_Path(1,NUMBER);    for(int i&#x3D;1;i&lt;SIZE;i++)    &#123;        cout &lt;&lt; &quot;顶点1&quot; &lt;&lt; &quot;到顶点&quot; &lt;&lt; i &lt;&lt; &quot;的最短距离&#x3D;&quot; &lt;&lt; Distance[i] &lt;&lt; endl;    &#125;     system(&quot;pause&quot;);    return 0;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>最小生成树(Kruskal算法)</title>
      <link href="/2020/11/11/zui-xiao-sheng-cheng-shu-kruskal-suan-fa/"/>
      <url>/2020/11/11/zui-xiao-sheng-cheng-shu-kruskal-suan-fa/</url>
      
        <content type="html"><![CDATA[<hr><blockquote><p>一下子就接触算法原理和一堆七七八八的术语概念，无疑是让人头疼的，因为无端出现这么多的信息，都不知道它的来历，又不知道这些信息到底有什么用，所以我们就从最简单的内容开始，将这个算法完整地梳理一下吧。</p></blockquote><hr><h2 id="1、知识脉络梳理"><a href="#1、知识脉络梳理" class="headerlink" title="1、知识脉络梳理"></a>1、知识脉络梳理</h2><h3 id="1、树形结构"><a href="#1、树形结构" class="headerlink" title="1、树形结构"></a>1、树形结构</h3><p>首先，先来看看一个简单的数据结构——树。<br>树形结构，从字面上来理解，就是像我们生活中常见的树长的很类似。在数据结构中我们无非就是将生活中的树倒过来看而已，也就是树根在上，树叶在下。这么设计其实也没什么特别的道理，只是在遍历树的时候，我们从树根开始，从树根往叶子节点出发。但是除了倒着放，其实我们也可以将他伸展开来放，例如下面的这棵树，其实也是一棵树</p><p><img src="/2020/11/11/zui-xiao-sheng-cheng-shu-kruskal-suan-fa/%E5%9B%BE1.png"></p><p>我们大致的想象一下，就像直接抓着树根将它拎起来，那么就自然变成了上图的样子了。</p><p>于是我们就发现，不管拎起是哪个节点，都会得到一棵树。也就是说，如果树根的位置对我们不再重要的话，树其实就等价于上面这样的图。</p><p>那么这样的图究竟是什么图呢？它有什么性质呢？所有的图都能看成是树吗？下面我们来看一下三种情况：</p><p><img src="/2020/11/11/zui-xiao-sheng-cheng-shu-kruskal-suan-fa/%E5%9B%BE2.png"></p><p>显然这三种情况<strong>都不是树</strong>。第一种是因为图中的边有方向了，一旦有了方向，图中连通的情况就被破坏了。我们都知道，树应该是全部连通的，也就是说你从任意一个节点开始，都可以走到树上任何位置。那么根据定义，<strong>不能全连通，肯定就不是树</strong>。情况2也不对，因为<strong>有了环</strong>，树是不应该有环的，大家应该没见过那种从树根还能再到树根的树吧，那不是成了老树精了？在我们定义中的树也是<strong>不能有环</strong>的，不然我们遍历的时候不是永远也找不到终点了吗？第三种情况则是因为有个别的点孤立在外，因此<strong>不能连通</strong>，所以也不是树。</p><p>所以总结一下，树就是可以全连通的（无向图），并且没有环的图。</p><h3 id="2、从图到树"><a href="#2、从图到树" class="headerlink" title="2、从图到树"></a>2、从图到树</h3><p>从上面的部分，其实我们可以发现，<strong>树的本质就是图</strong>，无非就是一些具有特殊性质的图。因此我们也经常能看到许多有关于树的算法会被纳入图论当中。</p><p>通过对树的观察，其实我们可以发现一条重要性质，对于一棵拥有n个节点的树而言，它会有n-1条边。因此如果超过n-1条边，证明当中一定存在环路，如果不理解的话，你可以简单画个图尝试一下。反之，如果小于n-1条边，那么一定存在不连通的部分。但我们需要注意，这个性质正向可以成立，反过来就不成立了，用数学中的概念来说就是，它是一个必要条件，但不是一个充分条件。也就是说并不是n个点和n-1条边就一定是树，这个画个图就很容易得出反例。</p><p>接下来我们就用这个性质来尝试解决一下由图转化成树的问题。</p><p>现在有一个稍微复杂的图，如下图：<br><img src="/2020/11/11/zui-xiao-sheng-cheng-shu-kruskal-suan-fa/%E5%9B%BE3.png"><br>那么我们现在就根据这一个图生成一棵能够连通所有节点的树。根据上述的性质，我们的方法很明确，无非就是两种办法：</p><p>第一种办法是删边，既然是一个复杂图，说明边的数量肯定要超过n-1的，所以我们可以尝试去删减掉一些边，最后留下一棵树就可以了。</p><p>第二种做法则是增边，也就是说我们从零开始，一开始先把所有的边全部撤掉，然后一条一条地往一个集合当中添加n-1条边，让它变成一棵树。</p><p>那这两种方法哪种更好呢？我们可以想一下，我们每一次在删除边的时候是不是都需要考虑到<strong>是否会破坏树的连通关系</strong>，因此添加边的做法明显优于删减边的做法。</p><p><img src="/2020/11/11/zui-xiao-sheng-cheng-shu-kruskal-suan-fa/%E5%9B%BE4.png"></p><p>可以看看上图，如果我们删除AB这条边，就会发现这个已经不是连通图了，那必然也不可能成为一棵树。要判断连通关系，最好的方法就是先删除这条边，然后试着从A点出发，看看能否到达B点，如果能到达，则认为这条边是可以删除的，但是如果这么做的话，一旦图很大时，<strong>每一次删除需要遍历整张图</strong>，那么效率就会很低。并且每一次删除后，由于图的结构会发生 变化，我们还需要对这些变化进行存储，但由于他是一直动态变化，存储这些结果十分困难。</p><p>因此，删除边的方式可行，但是十分麻烦。</p><p>至此，我们知道了其实所谓的最小生成树就是从一个图当中选取n-1条边将他变换为一棵树的算法</p><h3 id="3、生成树"><a href="#3、生成树" class="headerlink" title="3、生成树"></a>3、生成树</h3><p>我们暂且不考虑带权问题，就先假设所有的边都是等权重的。</p><p>那么现在我们知道要采用添加边的方式，那我们选择一条边时，应该怎么判断这条有没有必要添加到集合中去呢？</p><p>树有一条性质是，树上任意的两个点，它们之间的路径有且只有一条，如果存在两点之间的路径有两条，那么必然可以形成一个环。那么我们就可以知道如果当前两个点之间已经存在通路的时候，就证明那么当前这两个点连成的边就不能再添加了，否则一定会出现环。因此我们需要设计的算法要<strong>维护树上点的连通性</strong>。</p><p>但是这又会有一个新问题，我们知道，在树结构当中，<strong>连通性是可以传递的</strong>。如果两个点之间连了一条边，并不仅仅只是这两个点连通，还包括了所有与这两个点之间连通的点都连通了。下面来看一个例子：</p><p><img src="/2020/11/11/zui-xiao-sheng-cheng-shu-kruskal-suan-fa/%E5%9B%BE5.png"></p><p>这张图当中A和B连了一条边，这不仅仅是A和B连通，而是<strong>左半边的集合和右半边集合的连通</strong>。所以，虽然A只是和B连通了，但是和C也连通了。AC这条边也一样不能被加入了。也就是说A和B连通，其实是<strong>A所在的集合和B所在的集合合并</strong>的过程。看到集合的合并我们就可以想到并查集，并查集算法就是用来解决集合合并和查询问题的。那么，显然可以用并查集来维护图中这些点集的连通性。关于并查集，如果不知道的朋友可以点击一下<a href="https://blog.csdn.net/bjweimengshu/article/details/108332389">传送门</a>进行了解。</p><p>所以，我们现在就得到了生成树。</p><h3 id="4、从生成树到最小生成树"><a href="#4、从生成树到最小生成树" class="headerlink" title="4、从生成树到最小生成树"></a>4、从生成树到最小生成树</h3><p>现在我们就可以为图中的每条边都加上权重，我们的目标很明确，就是要使得最后生成的树的所有权重之和最小。</p><p>比如，看下面这张图，我们现在想要使生成的树上所有边的权重和最小。</p><p><img src="/2020/11/11/zui-xiao-sheng-cheng-shu-kruskal-suan-fa/%E5%9B%BE6.jpg"></p><p>根据贪心算法，我们<strong>显然希望用尽量短的边来连通树</strong>。所以Kruskal算法的原理非常简单，就是对这些边的权值进行排序，依次从短到长遍历这些边，然后通过并查集来查询正在遍历的这条边是否能够被添加，直到所有边都遍历结束。</p><h2 id="2、代码实现"><a href="#2、代码实现" class="headerlink" title="2、代码实现"></a>2、代码实现</h2><h3 id="1、完美图解"><a href="#1、完美图解" class="headerlink" title="1、完美图解"></a>1、完美图解</h3><p>下面图解出自陈小玉老师所主编的书《趣学算法》中，朋友们可以借助理解算法。<br><img src="/2020/11/11/zui-xiao-sheng-cheng-shu-kruskal-suan-fa/%E5%9B%BE7.jpg"><br><img src="/2020/11/11/zui-xiao-sheng-cheng-shu-kruskal-suan-fa/%E5%9B%BE8.jpg"><br><img src="/2020/11/11/zui-xiao-sheng-cheng-shu-kruskal-suan-fa/%E5%9B%BE9.jpg"><br><img src="/2020/11/11/zui-xiao-sheng-cheng-shu-kruskal-suan-fa/%E5%9B%BE10.jpg"><br><img src="/2020/11/11/zui-xiao-sheng-cheng-shu-kruskal-suan-fa/%E5%9B%BE11.jpg"><br><img src="/2020/11/11/zui-xiao-sheng-cheng-shu-kruskal-suan-fa/%E5%9B%BE12.jpg"></p><h3 id="2、代码实现-1"><a href="#2、代码实现-1" class="headerlink" title="2、代码实现"></a>2、代码实现</h3><pre class="line-numbers language-C++" data-language="C++"><code class="language-C++">#include &lt;iostream&gt;#include &lt;iomanip&gt;#define VERTS 6  &#x2F;&#x2F;图的顶点数using namespace std;&#x2F;&#x2F;顶点的类class Edge&#123;public:    int from,to;  &#x2F;&#x2F;边依附的两个顶点    int find,weight;  &#x2F;&#x2F;边的权重    Edge *next;&#125;;int v[VERTS+1];Edge *findmincost(Edge *head);void mintree(Edge *head);int main()&#123;    &#x2F;&#x2F;各边状况    int data[10][3]&#x3D;&#123;&#123;1,2,6&#125;,&#123;1,6,12&#125;,&#123;1,5,10&#125;,                     &#123;2,3,3&#125;,&#123;2,4,5&#125;,&#123;2,6,8&#125;,                     &#123;3,4,7&#125;,&#123;4,6,11&#125;,&#123;4,5,9&#125;,&#123;5,6,16&#125;&#125;;    Edge *head,*newnode,*ptr;    &#x2F;&#x2F;建立图的链表    head&#x3D;NULL;    cout &lt;&lt; &quot;创建图的链表 ：&quot; &lt;&lt; endl;    for(int i&#x3D;1;i&lt;&#x3D;VERTS;i++)    &#123;        for(int j&#x3D;0;j&lt;10;j++)        &#123;            if(data[j][0]&#x3D;&#x3D;i)            &#123;                newnode&#x3D;new Edge;                newnode-&gt;from&#x3D;data[j][0];                newnode-&gt;to&#x3D;data[j][1];                newnode-&gt;weight&#x3D;data[j][2];                newnode-&gt;find&#x3D;0;                newnode-&gt;next&#x3D;NULL;                if(head&#x3D;&#x3D;NULL)  &#x2F;&#x2F;如果头结点为空，则创建新节点                &#123;                    head&#x3D;newnode;                    head-&gt;next&#x3D;NULL;                    ptr&#x3D;head;                &#125;                else                &#123;                    ptr-&gt;next&#x3D;newnode;                    ptr&#x3D;ptr-&gt;next;                &#125;            &#125;        &#125;    &#125;    &#x2F;&#x2F;打印图的链表    ptr&#x3D;head;    while(ptr!&#x3D;NULL)    &#123;        cout &lt;&lt; &quot;起始顶点 [&quot; &lt;&lt; ptr-&gt;from &lt;&lt; &quot;]&quot; &lt;&lt; setw(8)              &lt;&lt; &quot;终止顶点 [&quot; &lt;&lt; ptr-&gt;to &lt;&lt; &quot;]&quot;  &lt;&lt; setw(8)              &lt;&lt; &quot;路径长度 [&quot; &lt;&lt; ptr-&gt;weight &lt;&lt; &quot;]&quot; &lt;&lt; endl;        ptr&#x3D;ptr-&gt;next;  &#x2F;&#x2F;指针后移    &#125;    &#x2F;&#x2F;创建最小生成树    cout &lt;&lt; &quot;建立最小成本生成树：&quot; &lt;&lt; endl;    mintree(head);    delete newnode;    system(&quot;pause&quot;);    return 0;&#125;&#x2F;&#x2F;找到权值最小的边Edge *findmincost(Edge *head)&#123;    int minval&#x3D;100;  &#x2F;&#x2F;设置初始最小值    Edge *retptr,*ptr;    ptr&#x3D;head;    while(ptr!&#x3D;NULL)    &#123;        if(ptr-&gt;weight&lt;minval &amp;&amp; ptr-&gt;find&#x3D;&#x3D;0)        &#123;            &#x2F;&#x2F;假如ptr-&gt;val的值小于minval            minval&#x3D;ptr-&gt;weight;  &#x2F;&#x2F;将ptr-&gt;val设置最小值            retptr&#x3D;ptr;  &#x2F;&#x2F;并且记录ptr        &#125;        ptr&#x3D;ptr-&gt;next;    &#125;    retptr-&gt;find&#x3D;1;    return retptr;&#125;&#x2F;&#x2F;Kruscal算法实现最小生成树void mintree(Edge *head)&#123;    Edge *ptr,*mceptr;    int result&#x3D;0;  &#x2F;&#x2F;标识变量    &#x2F;&#x2F;初始化    for(int i&#x3D;0;i&lt;&#x3D;VERTS;i++)    &#123;        v[i]&#x3D;0;    &#125;    ptr&#x3D;head;    while(ptr!&#x3D;NULL)  &#x2F;&#x2F;画图比较形象    &#123;        mceptr&#x3D;findmincost(head);        v[mceptr-&gt;from]++;        v[mceptr-&gt;to]++;        if(v[mceptr-&gt;from]&gt;1 &amp;&amp; v[mceptr-&gt;to]&gt;1)        &#123;            v[mceptr-&gt;from]--;            v[mceptr-&gt;to]--;            result&#x3D;1;        &#125;        else        &#123;            result&#x3D;0;        &#125;        if(result&#x3D;&#x3D;0)        &#123;            cout &lt;&lt; &quot;起始顶点 [&quot; &lt;&lt; mceptr-&gt;from &lt;&lt; &quot;]&quot; &lt;&lt; setw(8)                  &lt;&lt; &quot;终止顶点 [&quot; &lt;&lt; mceptr-&gt;to &lt;&lt; &quot;]&quot;  &lt;&lt; setw(8)                  &lt;&lt; &quot;路径长度 [&quot; &lt;&lt; mceptr-&gt;weight &lt;&lt; &quot;]&quot; &lt;&lt; endl;        &#125;        ptr&#x3D;ptr-&gt;next;    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图论，树形结构 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
